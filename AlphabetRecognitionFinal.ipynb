{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alphabet Recognition System using Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network (CNN) is a Deep Learning Algorithm widely used for character recognition. This algorithm identifies the alphabet from the given input image.\n",
    "\n",
    "The accuracy achieved using this algorithm is 93.42%.\n",
    "\n",
    "## 1. Anvil Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Authenticated OK\n"
     ]
    }
   ],
   "source": [
    "import anvil.server\n",
    "import anvil.media\n",
    "anvil.server.connect(\"44STZQZQTYAAVHHWGRPMXDRN-P5VUQGPD3HW5UMWJ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 161,082\n",
      "Trainable params: 161,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (32,32,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 26, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 501 images belonging to 26 classes.\n",
      "Found 260 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = 'Training',\n",
    "    target_size = (32,32),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    "\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory = 'Testing',\n",
    "    target_size = (32,32),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.1866 - accuracy: 0.9082 - val_loss: 0.7112 - val_accuracy: 0.8657\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.1769 - accuracy: 0.9301 - val_loss: 0.4118 - val_accuracy: 0.8662\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.1672 - accuracy: 0.9261 - val_loss: 0.2001 - val_accuracy: 0.9342\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                         steps_per_epoch = 16,\n",
    "                         epochs = 3,\n",
    "                         validation_data = test_generator,\n",
    "                         validation_steps = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving/Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('CNN_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('CNN_model.sav','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result):\n",
    "    if result[0][0] == 1:\n",
    "        return('a')\n",
    "    elif result[0][1] == 1:\n",
    "        return ('b')\n",
    "    elif result[0][2] == 1:\n",
    "        return ('c')\n",
    "    elif result[0][3] == 1:\n",
    "        return ('d')\n",
    "    elif result[0][4] == 1:\n",
    "        return ('e')\n",
    "    elif result[0][5] == 1:\n",
    "        return ('f')\n",
    "    elif result[0][6] == 1:\n",
    "        return ('g')\n",
    "    elif result[0][7] == 1:\n",
    "        return ('h')\n",
    "    elif result[0][8] == 1:\n",
    "        return ('i')\n",
    "    elif result[0][9] == 1:\n",
    "        return ('j')\n",
    "    elif result[0][10] == 1:\n",
    "        return ('k')\n",
    "    elif result[0][11] == 1:\n",
    "        return ('l')\n",
    "    elif result[0][12] == 1:\n",
    "        return ('m')\n",
    "    elif result[0][13] == 1:\n",
    "        return ('n')\n",
    "    elif result[0][14] == 1:\n",
    "        return ('o')\n",
    "    elif result[0][15] == 1:\n",
    "        return ('p')\n",
    "    elif result[0][16] == 1:\n",
    "        return ('q')\n",
    "    elif result[0][17] == 1:\n",
    "        return ('r')\n",
    "    elif result[0][18] == 1:\n",
    "        return ('s')\n",
    "    elif result[0][19] == 1:\n",
    "        return ('t')\n",
    "    elif result[0][20] == 1:\n",
    "        return ('u')\n",
    "    elif result[0][21] == 1:\n",
    "        return ('v')\n",
    "    elif result[0][22] == 1:\n",
    "        return ('w')\n",
    "    elif result[0][23] == 1:\n",
    "        return ('x')\n",
    "    elif result[0][24] == 1:\n",
    "        return ('y')\n",
    "    elif result[0][25] == 1:\n",
    "        return ('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = r'Testing\\e\\25.png'\n",
    "test_image = image.load_img(filename, target_size = (32,32))\n",
    "plt.imshow(test_image)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Alphabet is: e\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(test_image)\n",
    "result = get_result(result)\n",
    "print ('Predicted Alphabet is: {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predicting the Alphabet from the Input Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of code is receives the input image from the anvil website and returns the predicted alphabet back to the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def model_run(path):\n",
    "    with anvil.media.TempFile(path) as filename:\n",
    "        test_image = image.load_img(filename, target_size = (32,32))\n",
    "        test_image = image.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        result = model.predict(test_image)\n",
    "        result = get_result(result)\n",
    "        return ('Predicted Alphabet is: {}'.format(result))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
